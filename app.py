import streamlit as st
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from langchain import LLMChain, PromptTemplate
from langchain_groq import ChatGroq
import os
import re
import json
from dotenv import load_dotenv
import matplotlib.pyplot as plt

# Cargar variables de entorno
load_dotenv()

# Configurar el modelo LLM
os.environ["GROQ_API_KEY"] = os.getenv("GROQ_API_KEY")
llm = ChatGroq(
    model="gemma2-9b-it",
    temperature=0,
    max_tokens=None,
    timeout=None,
    max_retries=2,
)

noticias = [
    "Repsol, entre las 50 empresas que m치s responsabilidad hist칩rica tienen en el calentamiento global",
    "Amancio Ortega crea un fondo de 100 millones de euros para los afectados de la dana",
    "Freshly Cosmetics despide a 52 empleados en Reus, el 18% de la plantilla",
    "Wall Street y los mercados globales caen ante la incertidumbre por la guerra comercial y el temor a una recesi칩n",
    "El mercado de criptomonedas se desploma: Bitcoin cae a 80.000 d칩lares, las altcoins se hunden en medio de una fren칠tica liquidaci칩n",
    "Granada retrasa seis meses el inicio de la Zona de Bajas Emisiones, previsto hasta ahora para abril",
    "McDonald's donar치 a la Fundaci칩n Ronald McDonald todas las ganancias por ventas del Big Mac del 6 de diciembre",
    "El Gobierno autoriza a altos cargos p칰blicos a irse a Indra, Escribano, CEOE, Barcel칩, Iberdrola o Airbus",
    "Las aportaciones a los planes de pensiones caen 10.000 millones en los 칰ltimos cuatro a침os",
]

# Prompt para evaluar si la respuesta es suficientemente detallada
plantilla_evaluacion = """
Respuesta del inversor: {respuesta}
Eval칰a si la respuesta es suficientemente detallada o si es vaga e inespec칤fica.
Una respuesta detallada debe incluir una emoci칩n clara, una preocupaci칩n espec칤fica o una evaluaci칩n del impacto.

Si la respuesta es demasiado gen칠rica o ambigua, devuelve:
"Suficiente: No"
Si la respuesta es clara y bien fundamentada, devuelve:
"Suficiente: S칤"
"""
prompt_evaluacion = PromptTemplate(template=plantilla_evaluacion, input_variables=["respuesta"])
cadena_evaluacion = LLMChain(llm=llm, prompt=prompt_evaluacion)

# Prompt para analizar la reacci칩n del usuario y generar una pregunta de seguimiento
plantilla_reaccion = """
Reacci칩n del inversor: {reaccion}
Analiza el sentimiento y la preocupaci칩n expresada.  
Clasifica la preocupaci칩n principal en una de estas categor칤as:  
- Ambiental  
- Social  
- Gobernanza  
- Riesgo  

Si la respuesta es demasiado breve o poco clara, solicita m치s detalles de manera espec칤fica.  

Luego, genera una pregunta de seguimiento enfocada en la categor칤a detectada para profundizar en la opini칩n del inversor.  
Por ejemplo:  
- Si la categor칤a es Ambiental: "쮺칩mo crees que esto afecta la sostenibilidad del sector?"  
- Si la categor칤a es Social: "쮺rees que esto puede afectar la percepci칩n p칰blica de la empresa?"  
- Si la categor칤a es Gobernanza: "쮼ste evento te hace confiar m치s o menos en la gesti칩n de la empresa?"  
- Si la categor칤a es Riesgo: "쮺onsideras que esto aumenta la incertidumbre en el mercado?"  

Devuelve la categor칤a detectada y la pregunta de seguimiento en el siguiente formato:  
Categor칤a: [nombre de la categor칤a]  
Pregunta de seguimiento: [pregunta generada]
"""
prompt_reaccion = PromptTemplate(template=plantilla_reaccion, input_variables=["reaccion"])
cadena_reaccion = LLMChain(llm=llm, prompt=prompt_reaccion)

# Prompt para generar perfil ESG y de riesgo
plantilla_perfil = """
An치lisis de reacciones: {analisis}
Genera un perfil detallado del inversor basado en sus reacciones, enfoc치ndote en los pilares ESG (Ambiental, Social y Gobernanza) y su aversi칩n al riesgo. 
Asigna una puntuaci칩n de 0 a 100 para cada pilar ESG y para el riesgo, donde 0 indica ninguna preocupaci칩n y 100 m치xima preocupaci칩n o aversi칩n.
Devuelve las 4 puntuaciones en formato: Ambiental: [puntuaci칩n], Social: [puntuaci칩n], Gobernanza: [puntuaci칩n], Riesgo: [puntuaci칩n]
"""
prompt_perfil = PromptTemplate(template=plantilla_perfil, input_variables=["analisis"])
cadena_perfil = LLMChain(llm=llm, prompt=prompt_perfil)

# Inicializar estado en Streamlit
if "historial" not in st.session_state:
    st.session_state.historial = []
    st.session_state.contador = 0
    st.session_state.reacciones = []
    st.session_state.mostrada_noticia = False

st.title("Chatbot de An치lisis de Sentimiento")

# Mostrar historial
for mensaje in st.session_state.historial:
    with st.chat_message(mensaje["tipo"]):
        st.write(mensaje["contenido"])

# Mostrar noticia y pedir reacci칩n
if st.session_state.contador < len(noticias):
    if not st.session_state.mostrada_noticia:
        noticia = noticias[st.session_state.contador]
        with st.chat_message("bot", avatar="游뱄"):
            st.write(f"쯈u칠 opinas sobre esta noticia? {noticia}")
        st.session_state.historial.append({"tipo": "bot", "contenido": noticia})
        st.session_state.mostrada_noticia = True

    user_input = st.chat_input("Escribe tu respuesta aqu칤...")
    if user_input:
        st.session_state.historial.append({"tipo": "user", "contenido": user_input})
        st.session_state.reacciones.append(user_input)

        # Evaluamos si la respuesta es suficientemente detallada
        evaluacion = cadena_evaluacion.run(respuesta=user_input)
        suficiente_match = re.search(r"Suficiente: (S칤|No)", evaluacion)

        if suficiente_match and suficiente_match.group(1) == "No":
            analisis_reaccion = cadena_reaccion.run(reaccion=user_input)
            pregunta_match = re.search(r"Pregunta de seguimiento: (.+)", analisis_reaccion)

            with st.chat_message("bot", avatar="游뱄"):
                if pregunta_match:
                    st.write(f"{pregunta_match.group(1)}")
                else:
                    st.write("쯇odr칤as dar m치s detalles sobre tu opini칩n?")

            st.session_state.historial.append({"tipo": "bot", "contenido": pregunta_match.group(1) if pregunta_match else "쯇odr칤as dar m치s detalles sobre tu opini칩n?"})
        else:
            st.session_state.contador += 1
            st.session_state.mostrada_noticia = False
            st.rerun()
else:
    analisis_total = "\n".join(st.session_state.reacciones)
    perfil = cadena_perfil.run(analisis=analisis_total)
    with st.chat_message("bot", avatar="游뱄"):
        st.write(f"**Perfil del inversor:** {perfil}")

    st.session_state.historial.append({"tipo": "bot", "contenido": f"**Perfil del inversor:** {perfil}"})

    # Guardar en Google Sheets (opcional)
    # Aqu칤 podr칤as agregar la l칩gica para almacenar el perfil en la base de datos

st.success("Respuestas y perfil guardados correctamente.")  
